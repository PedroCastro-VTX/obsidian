#servidores
#ventrix 
#passo-a-passo

## âœ… Etapas para criar uma instÃ¢ncia Linux na AWS (via Console)

### 1. **Acesse o EC2**

- VÃ¡ para o painel da AWS: [https://console.aws.amazon.com/ec2/](https://console.aws.amazon.com/ec2/)
    
- Clique em **"Launch Instance"**
    

---

### 2. **ConfiguraÃ§Ãµes bÃ¡sicas**

#### a. **Nome da instÃ¢ncia**

- Exemplo: `meu-servidor-linux`
    

#### b. **Imagem de mÃ¡quina (AMI)**

Escolha uma dessas:

- **Amazon Linux 2** _(leve e otimizada para AWS)_
    
- **Ubuntu 22.04 LTS** _(boa para desenvolvimento geral)_
    
#### c. **Tipo de instÃ¢ncia**

- **t2.micro** (grÃ¡tis no Free Tier, ideal para testes)
    
- **t3.micro** (mais recente, se disponÃ­vel no seu Free Tier)
    

---

### 3. **Chave de acesso (SSH)**

- Crie ou selecione uma **chave PEM**
    
- Baixe e guarde com cuidado (vocÃª usarÃ¡ para se conectar via terminal/SSH)
    

---

### 4. **ConfiguraÃ§Ã£o de rede (Security Group)**

Crie ou use um grupo de seguranÃ§a com essas **regras de entrada**:

|Tipo|Protocolo|Porta|Origem|
|---|---|---|---|
|SSH|TCP|22|Seu IP (recomendado)|
|HTTP (opcional)|TCP|80|0.0.0.0/0|
|HTTPS (opcional)|TCP|443|0.0.0.0/0|
### 5. **Disco**

- 8 GB padrÃ£o (vocÃª pode ajustar)
    
- Tipo: **gp3** (SSD geral)
    

---

### 6. **LanÃ§ar instÃ¢ncia**

- Clique em **Launch**
    
- Aguarde a instÃ¢ncia iniciar
    

---

## ğŸ’» Conectando via SSH (Linux/macOS/WSL)

chmod 400 sua-chave.pem
ssh -i sua-chave.pem ec2-user@IP-PÃšBLICO

    Para Ubuntu, use ubuntu@IP ao invÃ©s de ec2-user@IP

## ğŸŒ 1. **Apontar o domÃ­nio para a instÃ¢ncia EC2**

### a. Obtenha o **IP pÃºblico da sua instÃ¢ncia**

- No painel do EC2 â†’ veja o campo **â€œIPv4 Public IPâ€**
    

### b. No seu provedor de domÃ­nio (GoDaddy, Registro.br, Cloudflare, etc):

- Crie um **registro A**:
    
    - Nome: `@` ou `www` (ou `app`, se quiser `app.seudominio.com`)
        
    - Tipo: `A`
        
    - Valor: **IP pÃºblico da instÃ¢ncia**
        
    - TTL: 300 (ou automÃ¡tico)
        

> Exemplo: @      A     13.201.45.123
www    A     13.201.45.123

## ğŸ§± 2. **Instalar o NGINX na EC2**

Depois de conectar via SSH:

# Para Amazon Linux 2:
sudo yum update -y
sudo amazon-linux-extras install nginx1 -y
sudo systemctl enable nginx
sudo systemctl start nginx

# Ou para Ubuntu:
sudo apt update && sudo apt install nginx -y
sudo systemctl enable nginx
sudo systemctl start nginx

Depois, acesse seu IP no navegador: `http://seu-ip` â€” deve aparecer a tela padrÃ£o do NGINX.


## ğŸ”’ 3. **Instalar HTTPS com Certbot (Let's Encrypt)**

### a. Instalar Certbot:

**Amazon Linux 2**:

sudo yum install -y epel-release
sudo yum install -y certbot python2-certbot-nginx

**Unbutu**
sudo apt install certbot python3-certbot-nginx -y

### b. Obter o certificado:
`sudo certbot --nginx`

Siga os passos:

- Informe o domÃ­nio (ex: `meusite.com`)
    
- Confirme o redirecionamento de HTTP â†’ HTTPS
    

### c. Verificar renovaÃ§Ã£o automÃ¡tica:
`sudo certbot renew --dry-run`

## ğŸŒ 4. **Testar o domÃ­nio**

Acesse `https://seusite.com` no navegador. Se tudo estiver certo:

- O certificado SSL serÃ¡ vÃ¡lido (https)
    
- O NGINX exibirÃ¡ sua pÃ¡gina padrÃ£o ou o conteÃºdo que vocÃª configurar


## ğŸ³ 1. **Instalar o Docker na sua VM Linux**

### ğŸ‘‰ Para Ubuntu:

sudo apt update
sudo apt install -y docker.io
sudo systemctl enable docker
sudo systemctl start docker

### ğŸ‘‰ Para Amazon Linux 2:

sudo yum update -y
sudo amazon-linux-extras enable docker
sudo yum install -y docker
sudo systemctl start docker
sudo systemctl enable docker
Adicione seu usuÃ¡rio ao grupo `docker` para evitar usar `sudo`:

`sudo usermod -aG docker ec2-user # ou ubuntu`
âš ï¸ FaÃ§a logout e login de novo para aplicar.

## ğŸ“¦ 2. **Rodar sua aplicaÃ§Ã£o em Docker**

Exemplo: vocÃª quer rodar um app Node.js, Flask, ou qualquer backend.
docker run -d \
  --name meuapp \
  -p 3000:3000 \
  minha-imagem:latest
Substitua `minha-imagem` pelo nome da sua imagem local ou do Docker Hub.

## ğŸŒ 3. **Configurar NGINX como proxy reverso**

Crie o arquivo de configuraÃ§Ã£o:

sudo nano /etc/nginx/conf.d/seusite.conf
Exemplo de configuraÃ§Ã£o para um app rodando em `localhost:3000`:

server {
    listen 80;
    server_name seusite.com www.seusite.com;

    location / {
        proxy_pass http://127.0.0.1:3000;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host $host;
        proxy_cache_bypass $http_upgrade;
    }
}

Reinicie o NGINX:
sudo nginx -t
sudo systemctl reload nginx
## ğŸ”’ 4. **Instalar HTTPS (SSL) com Certbot**

Se ainda nÃ£o fez, instale o Certbot:

### Ubuntu:

sudo apt install certbot python3-certbot-nginx -y

### Amazon Linux 2:

sudo yum install -y certbot python2-certbot-nginx

### Execute o Certbot:

sudo certbot --nginx

Escolha seu domÃ­nio e aceite redirecionar HTTP para HTTPS.

Excelente pergunta! VocÃª estÃ¡ diante de uma decisÃ£o **de arquitetura**: usar **mÃºltiplas VMs (EC2)** ou **containers Docker (microserviÃ§os)**. Aqui estÃ¡ um guia direto e estratÃ©gico pra decidir **quando usar VM ou Docker para cada serviÃ§o** que vocÃª mencionou:

---
Excelente pergunta! VocÃª estÃ¡ diante de uma decisÃ£o **de arquitetura**: usar **mÃºltiplas VMs (EC2)** ou **containers Docker (microserviÃ§os)**. Aqui estÃ¡ um guia direto e estratÃ©gico pra decidir **quando usar VM ou Docker para cada serviÃ§o** que vocÃª mencionou:
## âš™ï¸ VisÃ£o Geral dos 4 Componentes

| ServiÃ§o                            | Docker (microserviÃ§o) | VM separada (EC2)                        | RecomendaÃ§Ã£o                     |
| ---------------------------------- | --------------------- | ---------------------------------------- | -------------------------------- |
| **1. Servidor de AutenticaÃ§Ã£o**    | âœ… Sim                 | Opcional                                 | Docker, isolado                  |
| **2. Servidor de Dados/API**       | âœ… Sim                 | Opcional, se trÃ¡fego muito alto          | Docker (com ajuste de escala)    |
| **3. PostgreSQL**                  | âš ï¸ Sim, com cuidados  | âœ… Sim                                    | Melhor em VM ou RDS              |
| **4. NGINX (balanceador + HTTPS)** | âœ… Sim                 | âš ï¸ Sim, se alta carga ou mÃºltiplas zonas | Docker simples ou em uma VM leve |
## ğŸ§  DecisÃ£o prÃ¡tica (baseada em escalabilidade, custo e seguranÃ§a)

### âœ… O ideal para **fase inicial / MVP / produÃ§Ã£o controlada**:

| InstÃ¢ncia EC2           | O que roda nela (via Docker)                     |
| ----------------------- | ------------------------------------------------ |
| **EC2 #1 (App Server)** | AutenticaÃ§Ã£o + API (em containers separados)     |
| **EC2 #2 (Infra)**      | NGINX (reverse proxy + HTTPS), Traefik ou Caddy  |
| **EC2 #3 (Banco)**      | PostgreSQL (sem Docker, direto no SO ou via RDS) |
|                         |                                                  |
|                         |                                                  |
### ğŸ” Escalabilidade futura:

- VocÃª pode escalar horizontalmente os containers de API/autenticaÃ§Ã£o (Docker Swarm ou ECS).
    
- Pode usar **Amazon RDS** para gerenciar o PostgreSQL com backups automÃ¡ticos, failover etc.
    
- O NGINX pode ser substituÃ­do por **Application Load Balancer (ALB)** da AWS.
    

---

ğŸ§± Exemplo de stack com Docker Compose

version: '3.8'
services:
  auth:
    build: ./auth
    ports: [ "4000:4000" ]
    networks: [ "backend" ]

  api:
    build: ./api
    ports: [ "5000:5000" ]
    networks: [ "backend" ]

  nginx:
    image: nginx:latest
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
    ports: [ "80:80", "443:443" ]
    depends_on: [ "auth", "api" ]
    networks: [ "backend" ]

networks:
  backend:
  
PostgreSQL ficaria **fora** desse `docker-compose` em uma outra VM ou via RDS.

## âœ… ConclusÃ£o (recomendado para vocÃª)

ğŸ”’ **PostgreSQL**  
â†’ Rodar fora do Docker, em uma EC2 dedicada ou Amazon RDS  
ğŸ¯ **Motivo**: performance, seguranÃ§a e persistÃªncia

ğŸ“¦ **AutenticaÃ§Ã£o + API**  
â†’ Rodar juntos em containers, orquestrados com Docker Compose ou ECS

ğŸŒ **NGINX com HTTPS e balanceamento**  
â†’ Pode estar em um container simples ou numa pequena VM sÃ³ para isso


## ğŸ” EC2 Micro **â‰ ** MÃ¡quina Virtual diferente

- Na AWS, **cada instÃ¢ncia EC2 Ã© uma mÃ¡quina virtual separada**.
    
- Quando vocÃª escolhe uma **t2.micro / t3.micro / t3.small**, estÃ¡ apenas definindo o **tamanho (CPU/RAM)** daquela **VM individual**.
    
- Ou seja: **t2.micro = uma VM pequena**, nÃ£o um "tipo especial" de container ou microserviÃ§o.

## âœ… EntÃ£o, respondendo diretamente:

Se vocÃª criar 3 instÃ¢ncias EC2 (ex: uma para Nginx, uma para PostgreSQL e outra para API):

- VocÃª terÃ¡ **3 mÃ¡quinas virtuais separadas**
    
- Pode usar o tipo **micro, small ou medium**, dependendo da carga
    
- Pode rodar **1 ou mais containers Docker dentro de cada uma**

## ğŸ§  EstratÃ©gia recomendada com base no uso comum:

| ServiÃ§o            | EC2 separada?           | Tipo sugerido (Free Tier ou leve) | Docker?                                   |
| ------------------ | ----------------------- | --------------------------------- | ----------------------------------------- |
| NGINX + Certbot    | âœ… Sim (ou junto da API) | t2.micro ou t3.micro              | âœ… Sim (leve)                              |
| AutenticaÃ§Ã£o + API | âœ… Sim                   | t3.micro ou t3.small              | âœ… Sim                                     |
| PostgreSQL         | âœ… Sim (ou RDS)          | t3.small ou t3.medium             | âš ï¸ NÃ£o recomendado em Docker, se possÃ­vel |

## ğŸ§° Exemplo de setup com instÃ¢ncias pequenas (produÃ§Ã£o leve / MVP):

| InstÃ¢ncia EC2 | ServiÃ§os                              | Tipo                  |
| ------------- | ------------------------------------- | --------------------- |
| `ec2-nginx`   | NGINX + Certbot + Proxy               | t2.micro              |
| `ec2-app`     | API + AutenticaÃ§Ã£o (Docker)           | t3.small              |
| `ec2-db`      | PostgreSQL (sem Docker, direto no SO) | t3.small ou t3.medium |

## Alternativas:

- Se quiser **escalar automaticamente** e pagar menos por ociosidade, pode usar:
    
    - **ECS + Fargate** (containers gerenciados pela AWS)
        
    - **Lambda + API Gateway** (para APIs sem servidor)
        

---

## ğŸ” 1. **Auto Scaling com EC2 (VMs)**

### Como funciona:

VocÃª cria um **grupo de Auto Scaling**, define:

- **Imagem de mÃ¡quina (AMI)** com seu app
    
- **Limites de CPU, memÃ³ria ou trÃ¡fego**
    
- Quantidade mÃ­nima e mÃ¡xima de instÃ¢ncias
    

A AWS entÃ£o:

- Cria novas EC2 automaticamente se a carga subir
    
- Desliga as EC2 extras quando a carga cai
    

### Exemplo:

> Se a CPU mÃ©dia passar de 70% por 5 minutos, sobe mais 1 instÃ¢ncia EC2 com a mesma imagem.

### VocÃª precisa de:

- **EC2 Launch Template**
    
- **Auto Scaling Group**
    
- **Application Load Balancer (ALB)** ou NGINX como load balancer
    

---

## ğŸ³ 2. **Escalar com Docker usando ECS + Fargate (serverless containers)**

Essa Ã© a **alternativa moderna** para quem quer escalar containers sem gerenciar servidores.

### Vantagens:

- **Sem EC2 fixa** â†’ vocÃª sÃ³ paga pelos containers rodando
    
- **Auto scaling integrado** com mÃ©tricas de CPU, memÃ³ria ou requisiÃ§Ãµes
    
- **Gerenciado pela AWS**, sem precisar configurar mÃ¡quinas
    

### Como funciona:

- VocÃª empacota seu app (API, auth, etc) em **containers**
    
- Sobe no **Amazon Elastic Container Service (ECS)** com **Fargate**
    
- Define regras de escala (ex: â€œse CPU > 60%, criar mais containersâ€)
    

> O balanceamento Ã© feito com **ALB (Application Load Balancer)** que distribui o trÃ¡fego entre os containers.


## âš–ï¸ Comparativo rÃ¡pido: Auto Scaling EC2 vs ECS + Fargate

|Recurso|EC2 com Auto Scaling|ECS + Fargate (containers)|
|---|---|---|
|Gerenciamento de VM|âœ… Sim (vocÃª cuida)|âŒ NÃ£o (AWS cuida)|
|Escalabilidade|âœ… Boa|âœ… Excelente|
|Complexidade inicial|ğŸ”§ Moderada|ğŸ”§ Leve/moderada|
|Performance customizada|âœ… Alta (vocÃª escolhe)|ğŸ”„ AdaptÃ¡vel, depende da tarefa|
|Custo sob demanda|âš ï¸ Pode ser maior|âœ… Paga sÃ³ pelo uso real|
|Ideal para|Apps mais pesados|APIs, microsserviÃ§os, startups|
## ğŸ§  RecomendaÃ§Ã£o prÃ¡tica pra vocÃª

Se vocÃª:

- EstÃ¡ montando uma arquitetura moderna e escalÃ¡vel
    
- JÃ¡ estÃ¡ ou pretende usar Docker
    
- Quer evitar dor de cabeÃ§a com VMs
    

ğŸ‘‰ **Use ECS + Fargate** com auto scaling e ALB.

> Exemplo: sua API e Auth em containers â†’ escalam automaticamente com trÃ¡fego. Banco de dados continua fixo (em EC2 ou RDS).


## ğŸ§± Arquitetura Geral

| EC2                     | FunÃ§Ã£o                          | Docker?                         | Tipo sugerido   |
| ----------------------- | ------------------------------- | ------------------------------- | --------------- |
| **EC2 #1: App Server**  | API + AutenticaÃ§Ã£o (containers) | âœ… Sim                           | t3.small        |
| **EC2 #2: NGINX Proxy** | NGINX + Certbot (SSL) + Proxy   | âœ… Sim                           | t2.micro        |
| **EC2 #3: Banco**       | PostgreSQL                      | âŒ NÃ£o (direto no SO ou via RDS) | t3.small ou RDS |
# ğŸ–¥ï¸ EC2 #1 â€” App Server (Auth + API)

### Estrutura de diretÃ³rios:

/home/ec2-user/app/
â”œâ”€â”€ auth/
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ api/
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml

`docker-compose.yml`:

version: '3.8'

services:
  auth:
    build: ./auth
    ports:
      - "4000:4000"
    environment:
      - DB_URL=postgresql://user:pass@<db_ip>:5432/dbname
    restart: always
    networks:
      - backend

  api:
    build: ./api
    ports:
      - "5000:5000"
    environment:
      - DB_URL=postgresql://user:pass@<db_ip>:5432/dbname
    restart: always
    networks:
      - backend

networks:
  backend:

Substitua `<db_ip>` pelo IP privado da EC2 do banco.

# ğŸŒ EC2 #2 â€” NGINX Proxy com HTTPS
### Estrutura:

/home/ec2-user/nginx/
â”œâ”€â”€ nginx.conf
â”œâ”€â”€ docker-compose.yml

`nginx.conf` (exemplo bÃ¡sico):

events {}
http {
  server {
    listen 80;
    server_name seusite.com www.seusite.com;

    location /api/ {
      proxy_pass http://<app_server_ip>:5000/;
    }

    location /auth/ {
      proxy_pass http://<app_server_ip>:4000/;
    }
  }
}

`docker-compose.yml`:

version: '3.8'

services:
  nginx:
    image: nginx:latest
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
    ports:
      - "80:80"
      - "443:443"
    restart: always

Depois, instale o **Certbot no host** (fora do container) com:

sudo apt install certbot python3-certbot-nginx -y
sudo certbot --nginx
 
# ğŸ›¢ï¸ EC2 #3 â€” PostgreSQL

### Rodar diretamente no sistema (sem Docker):

sudo apt update
sudo apt install postgresql postgresql-contrib -y

### Configurar acesso:

- Edite o `postgresql.conf`:
 sudo nano /etc/postgresql/14/main/postgresql.conf

â†’ Altere `listen_addresses = '*'`

- Edite o `pg_hba.conf`:
sudo nano /etc/postgresql/14/main/pg_hba.conf

â†’ Adicione:
`host all all <app_server_private_ip>/32 md5`

-> Reinicie:
`sudo systemctl restart postgresql`

**Crie banco/usuÃ¡rio com:**
sudo -u postgres psql
CREATE USER user WITH PASSWORD 'pass';
CREATE DATABASE dbname;
GRANT ALL PRIVILEGES ON DATABASE dbname TO user;

## ğŸ“¡ ComunicaÃ§Ã£o entre instÃ¢ncias

- As EC2s precisam estar **na mesma VPC** e **sub-rede** para comunicaÃ§Ã£o via IP privado
    
- Libere as portas nos **Security Groups**:
    
    - EC2 API/Auth: portas 4000 e 5000 (acesso sÃ³ do NGINX)
        
    - EC2 PostgreSQL: porta 5432 (acesso sÃ³ do App Server)
        
    - EC2 NGINX: portas 80 e 443 (abertas para internet)

## ğŸ” Auto Scaling e Load Balancer (futuro)

Mais pra frente, vocÃª pode:

- Criar um **Application Load Balancer (ALB)** para distribuir para mÃºltiplas instÃ¢ncias do App Server
    
- Substituir EC2 + NGINX por ECS + Fargate
    
- Mover PostgreSQL para **RDS** gerenciado

# CONFIGURAÃ‡Ã•ES EC2'S:

[[ec_2_docker_architecture.yaml]]

# 1. Criar Application Load Balancer (ALB) com HTTPS

### Passo 1: Criar um certificado SSL no AWS Certificate Manager (ACM)

- VÃ¡ no Console AWS > Certificate Manager
    
- Clique em **Provisionar certificados**
    
- Escolha **Solicitar um certificado pÃºblico**
    
- Insira seu domÃ­nio (ex: `seusite.com` e `www.seusite.com`)
    
- Valide o domÃ­nio (por DNS ou email) â€” DNS Ã© mais rÃ¡pido, se seu domÃ­nio estiver na Route53
    
- Aguarde aprovaÃ§Ã£o (pode levar alguns minutos)

### Passo 2: Criar o Load Balancer

- Console AWS > EC2 > Load Balancers > Criar Load Balancer
    
- Escolha **Application Load Balancer**
    
- Nomeie o ALB (ex: `app-alb`)
    
- Escolha esquema: **internet-facing**
    
- Defina as zonas de disponibilidade que sua VPC usa
    
- Em **Listeners**, deixe HTTP na porta 80 e adicione HTTPS na porta 443
    
- Em **ConfiguraÃ§Ã£o SSL**, selecione o certificado do ACM criado

### Passo 3: Configurar grupos alvo (Target Groups)

- Crie um **Target Group** para suas EC2s do App Server (tipo: instÃ¢ncias, protocolo HTTP, porta 5000 ou 4000)
    
- Adicione as instÃ¢ncias EC2 com o serviÃ§o API e autenticaÃ§Ã£o para esse target group
    
- Configure health checks na porta correta (ex: `/health` se tiver endpoint de status)

### Passo 4: Configurar regras do Listener HTTPS

- No Listener HTTPS (porta 443), direcione o trÃ¡fego para o Target Group criado
    
- Opcional: No Listener HTTP (porta 80), configure redirecionamento para HTTPS para forÃ§ar seguranÃ§a

# 2. Configurar Security Groups para Load Balancer e EC2

- Crie Security Group para o ALB permitindo entrada nas portas 80 e 443
    
- Modifique Security Group das EC2 para permitir trÃ¡fego do SG do ALB nas portas 4000 e 5000

# 3. Criar regras de Auto Scaling

### Passo 1: Criar um Launch Template

- EC2 > Launch Templates > Criar template
    
- Configure a AMI, tipo de instÃ¢ncia (ex: t3.small), chave SSH, Security Group, User Data (script para iniciar Docker Compose)
    

Exemplo de **User Data** para rodar Docker Compose na inicializaÃ§Ã£o:

#!/bin/bash
cd /home/ec2-user/app
docker-compose up -d
### Passo 2: Criar Auto Scaling Group

- EC2 > Auto Scaling Groups > Criar grupo
    
- Selecione o Launch Template criado
    
- Configure zona e sub-redes (mÃ­nimo 1 instÃ¢ncia, mÃ¡ximo conforme desejar)
    
- Associe o Target Group do ALB criado
    
- Defina polÃ­ticas de escala:
    
    - Por exemplo, se CPU mÃ©dia > 70% por 5 minutos â†’ adiciona +1 instÃ¢ncia
        
    - Se CPU mÃ©dia < 40% por 10 minutos â†’ remove -1 instÃ¢ncia


# GRAFANA

### 1. Conectar Grafana ao CloudWatch

- No Grafana, adicione uma nova fonte de dados: escolha **CloudWatch**
    
- Configure as credenciais AWS (via IAM Role, Access Key ou perfil local)
    
- Se estiver rodando Grafana dentro da AWS (ex: EC2), pode usar **IAM Role** para facilitar

### 2. Criar dashboards

- ApÃ³s conectar, vocÃª pode criar painÃ©is que exibem mÃ©tricas de CPU, memÃ³ria, disco, rede, etc, para suas instÃ¢ncias EC2
    
- TambÃ©m pode monitorar grupos de Auto Scaling (mÃ©tricas como nÃºmero de instÃ¢ncias, status de health check)
    
- Use painÃ©is prontos da comunidade Grafana para EC2/Auto Scaling ou crie os seus personalizados

### 3. Alertas

- Grafana tambÃ©m permite configurar alertas com base em mÃ©tricas, enviando notificaÃ§Ãµes por email, Slack, Telegram, etc
    
- VocÃª pode complementar os alarmes do CloudWatch com alertas customizados no Grafana

### Dicas extras

- Se quiser mÃ©tricas mais detalhadas (ex: uso de memÃ³ria, processos dentro do container), instale o **CloudWatch Agent** na EC2
    
- Para monitorar Docker e containers, pode usar o **Prometheus** com **node_exporter** e **cAdvisor**, enviando dados para Grafana